# Generated by CodiumAI
import logging
from pathlib import Path

import pandas as pd
import pytest
from pydantic import ValidationError

from mlcompare.data.datasets import (
    BaseDataset,
    DatasetFactory,
    KaggleDataset,
    LocalDataset,
)

logger = logging.getLogger(__name__)


def create_csv_file(file_path: str | Path) -> None:
    two_column_data = {"A": [1, 2, 3], "B": [4, 5, 6]}
    data = pd.DataFrame(two_column_data)
    data.to_csv(file_path, index=False)


# Abstract base class with an abstract method `validate_data` shouldn't be instantiable
class TestBaseDataset:
    def test_init(self):
        with pytest.raises(TypeError):
            BaseDataset(
                target="target",
                drop=["col1"],
                onehotEncode=["col2"],
            )


class TestKaggleDataset:
    def test_init(self):
        dataset = KaggleDataset(
            user="some_user",
            dataset="some_dataset",
            file="some_file.csv",
            target="target",
            drop=["col1", "col2"],
            onehotEncode=["col3"],
        )

        assert dataset.user == "some_user"
        assert dataset.dataset == "some_dataset"
        assert dataset.file == "some_file.csv"
        assert dataset.target == "target"
        assert dataset.drop == ["col1", "col2"]
        assert dataset.onehot_encode == ["col3"]

    def test_init_without_optional_columns(self):
        KaggleDataset(
            user="user",
            dataset="dataset",
            file="file.csv",
            target="target",
        )

    def test_init_without_target(self):
        with pytest.raises(ValidationError):
            KaggleDataset(
                user="user",
                dataset="dataset",
                file="file.csv",
                drop=["col1"],
                onehotEncode=["col2"],
            )

    def test_special_characters_in_attributes(self):
        special_chars = "!@#$%^&*()"
        dataset = KaggleDataset(
            user=f"user{special_chars}",
            dataset=f"dataset{special_chars}",
            file=f"file{special_chars}.csv",
            target="target",
            drop=None,
            onehotEncode=None,
        )

        assert special_chars in dataset.user
        assert special_chars in dataset.dataset
        assert special_chars in dataset.file

    def test_length_of_attributes(self):
        long_string = "a" * 256
        KaggleDataset(
            user=long_string,
            dataset=long_string,
            file=f"{long_string}.csv",
            target="target",
        )

    def test_invalid_file(self):
        with pytest.raises(ValueError):
            dataset = KaggleDataset(
                user="user",
                dataset="dataset",
                file="file",
                target="target",
            )

            dataset.validate_data()


class TestLocalDataset:
    test_path = Path("local_dataset.csv")
    create_csv_file(test_path)

    def test_init(self):
        dataset = LocalDataset(
            path=self.test_path,
            target="target",
            drop=["col1", "col2"],
            onehotEncode=["col3"],
        )

        assert dataset.file_path == self.test_path
        assert dataset.target == "target"
        assert dataset.drop == ["col1", "col2"]
        assert dataset.onehot_encode == ["col3"]
        assert dataset.save_name == "local_dataset"

    def test_init_without_optional_columns(self):
        LocalDataset(
            path=self.test_path,
            target="target",
        )

    def test_str_path(self):
        dataset = LocalDataset(
            path="local_dataset.csv",
            target="target",
        )

        assert dataset.save_name == "local_dataset"

    def test_no_target(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                path=self.test_path,
                drop=["col1"],
                onehotEncode=["col2"],
            )

    def test_invalid_path_with_path_object(self):
        with pytest.raises(FileNotFoundError):
            LocalDataset(
                path=Path("file.csv"),
                target="target",
            )

    def test_invalid_path_with_str(self):
        with pytest.raises(FileNotFoundError):
            LocalDataset(
                path="file.csv",
                target="target",
            )

    def test_invalid_path_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                path=123,
                target="target",
            )

    def test_invalid_target_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                path=self.test_path,
                target=123,
            )

    def test_invalid_save_name_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                path=self.test_path,
                target="target",
                saveName=123,
            )


class TestDatasetFactory:
    test_path = Path("local_dataset.csv")
    test_path_string = "local_dataset.csv"
    create_csv_file(test_path)

    def test_init_local(self):
        params_list = [
            {
                "type": "local",
                "path": "local_dataset.csv",
                "target": "target",
            },
        ]

        factory = DatasetFactory(params_list)
        for dataset in factory:
            assert isinstance(dataset, LocalDataset)

    def test_init_kaggle(self):
        params_list = [
            {
                "type": "kaggle",
                "user": "user1",
                "dataset": "dataset1",
                "file": "file1.csv",
                "target": "target",
            },
            {
                "type": "kaggle",
                "user": "user2",
                "dataset": "dataset2",
                "file": "file2.csv",
                "target": "target",
            },
        ]

        factory = DatasetFactory(params_list)
        for dataset in factory:
            assert isinstance(dataset, KaggleDataset)

    def init_mixed(self):
        params_list = [
            {
                "type": "kaggle",
                "user": "user1",
                "dataset": "dataset1",
                "file": "file1.csv",
                "target": "target",
            },
            {
                "type": "kaggle",
                "user": "user2",
                "dataset": "dataset2",
                "file": "file2.csv",
                "target": "target",
            },
            {
                "type": "local",
                "file": "local_dataset.csv",
                "target": "target",
            },
        ]

        datasets = DatasetFactory(params_list)
        for dataset in datasets:
            assert isinstance(dataset, BaseDataset)

    def test_invalid_type(self):
        with pytest.raises(ValueError):
            params_list = [
                {
                    "type": "invalid",
                    "file": "local_dataset.csv",
                    "target": "target",
                },
            ]

            datasets = DatasetFactory(params_list)
            for dataset in datasets:
                pass

    def test_invalid_type_type(self):
        with pytest.raises(ValueError):
            params_list = [
                {
                    "type": 123,
                    "file": "local_dataset.csv",
                    "target": "target",
                },
            ]

            datasets = DatasetFactory(params_list)
            for dataset in datasets:
                pass
