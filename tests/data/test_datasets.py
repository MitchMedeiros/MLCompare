# Generated by CodiumAI
import logging
from pathlib import Path

import pandas as pd
import pytest
from pydantic import ValidationError

from mlcompare.data.datasets import (
    BaseDataset,
    DatasetFactory,
    DatasetType,
    KaggleDataset,
    LocalDataset,
)

logger = logging.getLogger(__name__)


class TestDatasetType:
    def test_init_for_valid_str(self):
        assert DatasetType("kaggle") == DatasetType.KAGGLE
        assert DatasetType("local") == DatasetType.LOCAL

    def test_invalid_str(self):
        with pytest.raises(ValueError):
            DatasetType("random")

    def test_invalid_type(self):
        with pytest.raises(ValueError):
            DatasetType(123)


# Abstract base class with an abstract method `validate_data` shouldn't be instantiable
class TestBaseDataset:
    def test_init(self):
        with pytest.raises(TypeError):
            BaseDataset(
                target_column="target",
                columns_to_drop=["col1"],
                columns_to_onehot_encode=["col2"],
            )


class TestKaggleDataset:
    def test_init(self):
        dataset = KaggleDataset(
            username="some_user",
            dataset_name="some_dataset",
            file_name="some_file.csv",
            target_column="target",
            columns_to_drop=["col1", "col2"],
            columns_to_onehot_encode=["col3"],
        )

        assert dataset.username == "some_user"
        assert dataset.dataset_name == "some_dataset"
        assert dataset.file_name == "some_file.csv"
        assert dataset.target_column == "target"
        assert dataset.columns_to_drop == ["col1", "col2"]
        assert dataset.columns_to_onehot_encode == ["col3"]

    def test_init_without_optional_columns(self):
        KaggleDataset(
            username="user",
            dataset_name="dataset",
            file_name="file.csv",
            target_column="target",
        )

    def test_init_without_target(self):
        with pytest.raises(ValidationError):
            KaggleDataset(
                username="user",
                dataset_name="dataset",
                file_name="file.csv",
                columns_to_drop=["col1"],
                columns_to_onehot_encode=["col2"],
            )

    def test_special_characters_in_attributes(self):
        special_chars = "!@#$%^&*()"
        dataset = KaggleDataset(
            username=f"user{special_chars}",
            dataset_name=f"dataset{special_chars}",
            file_name=f"file{special_chars}.csv",
            target_column="target",
            columns_to_drop=None,
            columns_to_onehot_encode=None,
        )

        assert special_chars in dataset.username
        assert special_chars in dataset.dataset_name
        assert special_chars in dataset.file_name

    def test_length_of_attributes(self):
        long_string = "a" * 256
        KaggleDataset(
            username=long_string,
            dataset_name=long_string,
            file_name=f"{long_string}.csv",
            target_column="target",
        )

    def test_invalid_file_name(self):
        with pytest.raises(ValueError):
            dataset = KaggleDataset(
                username="user",
                dataset_name="dataset",
                file_name="file",
                target_column="target",
            )

            dataset.validate_data()


class TestLocalDataset:
    test_path = Path("local_dataset.csv")
    two_column_data = {"A": [1, 2, 3], "B": [4, 5, 6]}
    data = pd.DataFrame(two_column_data)
    data.to_csv(test_path, index=False)

    def test_init(self):
        dataset = LocalDataset(
            file_path=self.test_path,
            target_column="target",
            columns_to_drop=["col1", "col2"],
            columns_to_onehot_encode=["col3"],
        )

        assert dataset.file_path == self.test_path
        assert dataset.target_column == "target"
        assert dataset.columns_to_drop == ["col1", "col2"]
        assert dataset.columns_to_onehot_encode == ["col3"]
        assert dataset.save_name == "local_dataset"

    def test_init_without_optional_columns(self):
        LocalDataset(
            file_path=self.test_path,
            target_column="target",
        )

    def test_str_file_path(self):
        dataset = LocalDataset(
            file_path="local_dataset.csv",
            target_column="target",
        )

        assert dataset.save_name == "local_dataset"

    def test_no_target(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                file_path=self.test_path,
                columns_to_drop=["col1"],
                columns_to_onehot_encode=["col2"],
            )

    def test_invalid_file_path_with_path_object(self):
        with pytest.raises(FileNotFoundError):
            LocalDataset(
                file_path=Path("file.csv"),
                target_column="target",
            )

    def test_invalid_file_path_with_str(self):
        with pytest.raises(FileNotFoundError):
            LocalDataset(
                file_path="file.csv",
                target_column="target",
            )

    def test_invalid_file_path_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                file_path=123,
                target_column="target",
            )

    def test_invalid_target_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                file_path=self.test_path,
                target_column=123,
            )

    def test_invalid_save_name_type(self):
        with pytest.raises(ValidationError):
            LocalDataset(
                file_path=self.test_path,
                target_column="target",
                save_name=123,
            )


class TestDatasetFactory:
    def test_create_kaggle_dataset(self):
        dataset = DatasetFactory.create(
            dataset_type=DatasetType.KAGGLE,
            username="some_user",
            dataset_name="some_dataset",
            file_name="some_file.csv",
            target_column="target",
            columns_to_drop=["col1", "col2"],
            columns_to_onehot_encode=["col3"],
        )

        assert isinstance(dataset, KaggleDataset)
        assert dataset.username == "some_user"
        assert dataset.dataset_name == "some_dataset"
        assert dataset.file_name == "some_file.csv"
        assert dataset.target_column == "target"
        assert dataset.columns_to_drop == ["col1", "col2"]
        assert dataset.columns_to_onehot_encode == ["col3"]

    def test_create_local_dataset(self):
        test_path = Path("local_dataset.csv")
        two_column_data = {"A": [1, 2, 3], "B": [4, 5, 6]}
        data = pd.DataFrame(two_column_data)
        data.to_csv(test_path, index=False)

        dataset = DatasetFactory.create(
            dataset_type=DatasetType.LOCAL,
            file_path=test_path,
            target_column="target",
            columns_to_drop=["col1", "col2"],
            columns_to_onehot_encode=["col3"],
        )

        assert isinstance(dataset, LocalDataset)
        assert dataset.file_path == test_path
        assert dataset.target_column == "target"
        assert dataset.columns_to_drop == ["col1", "col2"]
        assert dataset.columns_to_onehot_encode == ["col3"]
        assert dataset.save_name == "local_dataset"

        test_path.unlink()

    def test_invalid_dataset_type(self):
        with pytest.raises(ValueError):
            DatasetFactory.create(
                dataset_type="local",
                username="some_user",
                dataset_name="some_dataset",
                file_name="some_file.csv",
                target_column="target",
                columns_to_drop=["col1", "col2"],
                columns_to_onehot_encode=["col3"],
            )
